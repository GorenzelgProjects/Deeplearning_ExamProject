{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Source of inspiriration: https://huggingface.co/course/chapter7/7?fw=tf and https://huggingface.co/satvikag/chatbot?text=Hey+my+name+is+Clara%21+How+are+you%3F\n",
    "##Used to test the models we had created.\n",
    "##Also have some selfmade code for context extration, which is used in the main file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "import collections\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import create_optimizer\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at Gorenzelg/bert-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6535553932189941, 'start': 213, 'end': 221, 'answer': '$91.4939'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"Gorenzelg/bert-finetuned-squad\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "\n",
    "context = \"\"\"\n",
    "The product's name is Pendleton, with the description; Pendleton Women's Western Horizons Wool Coat. We have 20 on stock, and the new price for the product is $149.99 with a 61 percent discount.\n",
    "Make a saving of $91.4939!\n",
    "\"\"\"\n",
    "question = \"how much can i save ?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at Gorenzelg/bert-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9433984756469727, 'start': 141, 'end': 147, 'answer': '$81.98'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"Gorenzelg/bert-finetuned-squad\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "\n",
    "context = \"\"\"\n",
    "The description of the product is The Big Bang Theory: The Complete Series (DVD). We have 42 on stock, and the new price for the product is $81.98 with a 50 percent discount. Make a saving of $40.989999999999995!\n",
    "\"\"\"\n",
    "\n",
    "question = \"what is the price for big bang theory?\"\n",
    "\n",
    "print(question_answerer(question=question, context=context))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at ./bert_Finetuned_Squad_Local.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.5538567304611206,\n",
       " 'start': 35,\n",
       " 'end': 77,\n",
       " 'answer': 'Arthur Christmas (Two Discs: Blu-ray / DVD'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"./bert_Finetuned_Squad_Local\"\n",
    "question_answerer = pipeline(\"question-answering\",model=model_checkpoint)\n",
    "\n",
    "context = \"\"\"\n",
    "The description of the product is Arthur Christmas (Two Discs: Blu-ray / DVD). We have 11,220 on stock, and the new price for the product is $9.60 with a 50 percent discount. Make a saving of $4.799999999999999!\n",
    "\"\"\"\n",
    "\n",
    "question1 = \"What is this product?\"\n",
    "question_answerer(question=question1, context=context)\n",
    "#for i in range(len(question)):\n",
    "    #question1 = question[i]\n",
    "    #print(question_answerer(question=question1, context=context))\n",
    "    #print(type(question_answerer(question=question1, context=context)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "##Selfmade code to extract the context part from dot to dot, where the answer is found.\n",
    "\n",
    "##Finds the context from the two nearest dots confining our answer\n",
    "def proper_context(context,question):\n",
    "\n",
    "    #Loading in the ID's\n",
    "    model_checkpoint = \"./bert_Finetuned_Squad_Local\"\n",
    "    question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "    ab = question_answerer(question=question, context=context)\n",
    "    \n",
    "    #Saving start and end ID of answer\n",
    "    start = ab[\"start\"]\n",
    "    end = ab[\"end\"]\n",
    "\n",
    "    dots = []\n",
    "\n",
    "    #Finds the dots in the senence\n",
    "    for idx, letters in enumerate(context):\n",
    "        if letters == \".\" and context[idx+1] == \" \":\n",
    "            dots.append(idx)\n",
    "    #print(dots)\n",
    "    start_context = []\n",
    "    end_context = []\n",
    "    \n",
    "    #measuring the dot's distance from there start and end ID of answer\n",
    "    for i in range(len(dots)):\n",
    "        a = np.abs(dots[i]-start)\n",
    "        b = np.abs(dots[i]-end)\n",
    "        start_context.append(a)\n",
    "        end_context.append(b)\n",
    "\n",
    "    #Finding the closest dots on each side.\n",
    "    a = np.argmin(start_context)\n",
    "    idx_start = dots[a]\n",
    "    end_context.pop(a)\n",
    "    b = np.argmin(end_context)\n",
    "    #dots.pop(a)\n",
    "    idx_end = dots[b]\n",
    "    #print(idx_end)\n",
    "    done = np.sort(np.array([int(idx_start),int(idx_end)]))\n",
    "\n",
    "    proper_context = context[done[0]+2:done[1]]\n",
    "\n",
    "    return proper_context\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at Gorenzelg/bert-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 42 on stock, and the new price for the product is $81.98 with a 50 percent discount\n"
     ]
    }
   ],
   "source": [
    "print(proper_context(context,question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "##Selfmade code to extract the context part from dot to dot, where the answer is found.\n",
    "\n",
    "##Finds the context from the two nearest dots confining our answer\n",
    "def proper_context(context,question):\n",
    "\n",
    "    #Loading in the ID's\n",
    "    model_checkpoint = \"./bert_Finetuned_Squad_Local\"\n",
    "    question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "    Answer = question_answerer(question=question, context=context)\n",
    "    \n",
    "    #Saving start and end ID of answer\n",
    "    start = ab[\"start\"]\n",
    "    end = ab[\"end\"]\n",
    "\n",
    "    dots = []\n",
    "\n",
    "    #Finds the dots in the senence\n",
    "    for idx, letters in enumerate(context):\n",
    "        if letters == \".\" and context[idx+1] == \" \":\n",
    "            dots.append(idx)\n",
    "    #print(dots)\n",
    "    start_context = []\n",
    "    end_context = []\n",
    "    \n",
    "    #measuring the dot's distance from there start and end ID of answer\n",
    "    for i in range(len(dots)):\n",
    "        a = np.abs(dots[i]-start)\n",
    "        b = np.abs(dots[i]-end)\n",
    "        start_context.append(a)\n",
    "        end_context.append(b)\n",
    "\n",
    "    #Finding the closest dots on each side.\n",
    "    a = np.argmin(start_context)\n",
    "    idx_start = dots[a]\n",
    "    end_context.pop(a)\n",
    "    b = np.argmin(end_context)\n",
    "    #dots.pop(a)\n",
    "    idx_end = dots[b]\n",
    "    #print(idx_end)\n",
    "    done = np.sort(np.array([int(idx_start),int(idx_end)]))\n",
    "\n",
    "    proper_context = context[done[0]+2:done[1]]\n",
    "\n",
    "    return proper_context, Answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
