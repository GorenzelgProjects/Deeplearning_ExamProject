{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a15a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from model import NeuralNet\n",
    "from nltk_utils import bag_of_words, tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tkinter import *\n",
    "\n",
    "from tkinter import *\n",
    "from datetime import datetime\n",
    "import re\n",
    "from tkinter import messagebox\n",
    "from tkinter.font import Font\n",
    "import textwrap\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18d33ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at ./bert_Finetuned_Squad_Local.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Setting up hyperparameters and api connections\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "OPEN_API_KEY=\"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\"\n",
    "openai.api_key = OPEN_API_KEY\n",
    "#------------------------------------------------------------------------------------\n",
    "#Loading in the ID's\n",
    "model_checkpoint = \"./bert_Finetuned_Squad_Local\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "model_embedding = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v1')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# remove these words from stop words\n",
    "stopword_exceptions = ['not']\n",
    " \n",
    "# update the stopwords list without the words above\n",
    "all_stopwords = [el for el in stopwords if el not in stopword_exceptions]\n",
    "\n",
    "with open(\"./Amazon_data.txt\") as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "sentences_embeddings = model_embedding.encode(sentences)\n",
    "\n",
    "short_term_embedding = 0\n",
    "short_term_original = 0\n",
    "\n",
    "memory_weight_1 = 0.40\n",
    "memory_weight_2 = 0.60\n",
    "\n",
    "q_weight = 0.10\n",
    "a_weight = 0.90\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "with open('intents.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "item_categories = [\n",
    "    'description', \n",
    "    'price',\n",
    "    'rating',\n",
    "    'stock',\n",
    "    'discount',\n",
    "    'saving']\n",
    "\n",
    "search_tags = [\n",
    "    \"lowest\",\n",
    "    \"highest\",\n",
    "    \"lower than\",\n",
    "    \"higher than\"]\n",
    "\n",
    "skip_tags = [\n",
    "    \"contextual\"]\n",
    "\n",
    "item_embeddings = model_embedding.encode(item_categories)\n",
    "\n",
    "konf_pct = 0.92\n",
    "\n",
    "bubbles = []\n",
    "bubble_move = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb943ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(word):\n",
    "    word_list = word.split()\n",
    "\n",
    "    if len(word_list) > 1:\n",
    "        temp_word = []\n",
    "        for ele in word_list:\n",
    "            if ele not in all_stopwords:\n",
    "                temp_word.append(ele)\n",
    "            word = ' '.join(temp_word)\n",
    "            \n",
    "    return word\n",
    "\n",
    "def replace_word(word):\n",
    "    word_list = word.split()\n",
    "\n",
    "    if len(word_list) > 1:\n",
    "        temp_word = []\n",
    "        for ele in word_list:\n",
    "            temp_word.append(ele.replace(\"cheapest\",\"lowest\").replace(\"cheaper\",\"lower\").replace(\"cheap\",\"low\"))\n",
    "            word = ' '.join(temp_word)\n",
    "            \n",
    "    else:\n",
    "        word = word.replace(\"cheapest\",\"lowest\").replace(\"cheaper\",\"lower\").replace(\"cheap\",\"low\")\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247eb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to GPT3 Paraphrasing API\n",
    "\n",
    "#Key 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\n",
    "def gpt_call(answer):  \n",
    "    response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=\"Please rewrite this sentence: {}\".format(answer),\n",
    "    temperature=0.7,\n",
    "    max_tokens=709,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0)\n",
    "    \n",
    "    #print(response.choices[0].text)\n",
    "    \n",
    "    #final_answer = 0\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4797146",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finds the context from the two nearest dots confining our answer\n",
    "def proper_context(context,question):\n",
    "    \n",
    "    answer = question_answerer(question=question, context=context)\n",
    "    #Saving start and end ID of answer\n",
    "    start = answer[\"start\"]\n",
    "    end = answer[\"end\"]\n",
    "\n",
    "    dots = []\n",
    "\n",
    "    #Finds the dots in the senence\n",
    "    for idx, letters in enumerate(context):\n",
    "        if letters == \".\" and context[idx+1] == \" \":\n",
    "            dots.append(idx)\n",
    "    #print(dots)\n",
    "    start_context = []\n",
    "    end_context = []\n",
    "    \n",
    "    #measuring the dot's distance from there start and end ID of answer\n",
    "    for i in range(len(dots)):\n",
    "        a = dots[i]-start\n",
    "        b = dots[i]-end\n",
    "        start_context.append(a)\n",
    "        end_context.append(b)\n",
    "\n",
    "    #Finding the closest dots on each side.\n",
    "    #a = np.argmin(start_context)\n",
    "    start_context = np.array(start_context)\n",
    "\n",
    "    dots_before_index = np.where(start_context[:] <= 0)[0]\n",
    "    dots_before_value = np.amax(start_context[dots_before_index])\n",
    "    dots_before = np.where(start_context[:] == dots_before_value)[0]\n",
    "\n",
    "    a = dots_before[0]\n",
    "    \n",
    "\n",
    "    end_context = np.array(end_context)\n",
    "\n",
    "    dots_after_index = np.where(end_context[:] >= 0)[0]\n",
    "    dots_after_value = np.amin(end_context[dots_after_index])\n",
    "    dots_after = np.where(end_context[:] == dots_after_value)[0]\n",
    "\n",
    "    b = dots_after[0]\n",
    "\n",
    "    #dots.pop(a)\n",
    "    idx_start = dots[a]\n",
    "    idx_end = dots[b]\n",
    "    #print(idx_end)\n",
    "    done = np.sort(np.array([int(idx_start),int(idx_end)]))\n",
    "\n",
    "    proper_context = context[done[0]+2:done[1]+1]\n",
    "\n",
    "    return proper_context, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151f3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence Embedding with Short Term Memory\n",
    "def context_search(question, question_embedding, short_team_embedding, first_question=True):\n",
    "    compare_embedding_mean = []\n",
    "\n",
    "    history_question = ''\n",
    "\n",
    "    if first_question:       \n",
    "\n",
    "        for sentence, embedding in zip(sentences, sentences_embeddings):\n",
    "            compare_embedding_mean.append(np.mean(np.square(question_embedding - embedding)).mean())\n",
    "\n",
    "        best_compare_index = np.argmin(compare_embedding_mean)\n",
    "        best_sentence = sentences[best_compare_index]\n",
    "        \n",
    "        history_question += question + ' ' + best_sentence + ' '\n",
    "\n",
    "        short_team_embedding = (question_embedding*q_weight) + (sentences_embeddings[best_compare_index]*a_weight)\n",
    "\n",
    "        first_question = False\n",
    "\n",
    "        print(\"Context:\", best_sentence)\n",
    "        print('________________________________________________')\n",
    "\n",
    "    else:\n",
    "\n",
    "        short_team_embedding = (short_team_embedding*memory_weight_1) + (question_embedding*memory_weight_2)\n",
    "        \n",
    "        for sentence, embedding in zip(sentences, sentences_embeddings):\n",
    "\n",
    "            pair_CSM = np.dot(short_team_embedding,embedding)/(norm(short_team_embedding)*norm(embedding))\n",
    "\n",
    "            compare_embedding_mean.append(pair_CSM)\n",
    "\n",
    "        sorted_index = np.argsort(compare_embedding_mean).tolist()\n",
    "        sorted_embeddings = []\n",
    "        sorted_context = []\n",
    "        for i in sorted_index:\n",
    "            sorted_embeddings.append(compare_embedding_mean[i])\n",
    "            sorted_context.append(sentences[i])\n",
    "\n",
    "        best_compare_index = np.argmax(compare_embedding_mean)\n",
    "        best_sentence = sentences[best_compare_index]\n",
    "        history_question += ' ' + best_sentence + ' '\n",
    "\n",
    "        short_team_embedding = (short_team_embedding*memory_weight_1) + (sentences_embeddings[best_compare_index]*memory_weight_2)\n",
    "\n",
    "        print('------------------------------------------------')\n",
    "        print(\"Context:\", best_sentence)\n",
    "        print('________________________________________________')\n",
    "\n",
    "    return best_sentence, short_team_embedding, first_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45a9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Neural Network (FFNN) contextual chat function \n",
    "def general_chat(data_pd, question, question_short_embedding):\n",
    "    bot_name = \"Bot\"\n",
    "    match_index = 0\n",
    "    answer = ''\n",
    "    true_answer = False\n",
    "    search_context = False\n",
    "    q_to_a = False\n",
    "\n",
    "    question = tokenize(question)\n",
    "    X = bag_of_words(question, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "    item_tag = ''\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > konf_pct:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                item_tag = tag\n",
    "                if item_tag in skip_tags:\n",
    "                    true_answer = False\n",
    "                    search_context = True\n",
    "                    q_to_a = True\n",
    "                    return answer, true_answer, search_context, q_to_a, match_index\n",
    "\n",
    "                elif item_tag not in search_tags and item_tag not in skip_tags:\n",
    "                    answer = random.choice(intent['responses'])\n",
    "                    true_answer = True\n",
    "                    search_context = False\n",
    "                    q_to_a = False\n",
    "                    return answer, true_answer, search_context, q_to_a, match_index\n",
    "                elif item_tag in search_tags and item_tag not in skip_tags:\n",
    "                    compare_embedding_mean = []\n",
    "                    for sentence, embedding in zip(item_categories, item_embeddings):\n",
    "                        #print(\"Context:\", sentence)\n",
    "                        compare_embedding_mean.append(np.mean(np.square(question_short_embedding - embedding)).mean())\n",
    "\n",
    "                    best_compare_index = np.argmin(compare_embedding_mean)\n",
    "                    search_item = item_categories[best_compare_index]\n",
    "                    print(item_tag, search_item)\n",
    "                    answer, match_index = general_search(data_pd, search_type=item_tag, search_value=0, search_item=search_item)\n",
    "                    \n",
    "                    if item_tag == \"lower than\" or item_tag == \"higher than\":\n",
    "                        pass\n",
    "\n",
    "                    true_answer = False\n",
    "                    search_context = False\n",
    "                    q_to_a = True\n",
    "                    return answer, true_answer, search_context, q_to_a, match_index\n",
    "    else:\n",
    "        true_answer = False\n",
    "        search_context = True\n",
    "        q_to_a = True\n",
    "        return answer, true_answer, search_context, q_to_a, match_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcccb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_panda(data):\n",
    "    discount = []\n",
    "    saving = []\n",
    "    price = []\n",
    "    stock = []\n",
    "    sale = []\n",
    "    rating = []\n",
    "    for i in range(len(data)):\n",
    "        temp_stock = str(data[i,3]).replace(u'\\uff0c',',').replace(\",\",\"\")\n",
    "        discount.append((1-float(data[i,1][1:].replace(u'\\uff0c',',').replace(\",\",\"\"))/float(data[i,4][1:].replace(u'\\uff0c',',').replace(\",\",\"\")))*100)\n",
    "        saving.append(float(data[i,4][1:].replace(u'\\uff0c',',').replace(\",\",\"\"))-float(data[i,1][1:].replace(u'\\uff0c',',').replace(\",\",\"\")))\n",
    "        price.append(float(data[i,1][1:].replace(u'\\uff0c',',').replace(\",\",\"\")))\n",
    "        sale.append(float(data[i,4][1:].replace(u'\\uff0c',',').replace(\",\",\"\")))\n",
    "        stock.append(float(temp_stock))\n",
    "        rating.append(float(data[i,2]))\n",
    "    data_dict = {\n",
    "        'description': data[:,0], \n",
    "        'price': price,\n",
    "        'rating': rating,\n",
    "        'stock': stock,\n",
    "        'sale': sale,\n",
    "        'discount': discount,\n",
    "        'saving': saving\n",
    "    }\n",
    "\n",
    "    data_pd = pd.DataFrame(data_dict)\n",
    "\n",
    "    return data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0005d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General search function\n",
    "def general_search(data, search_type='lowest', search_value=0, search_item='price'):\n",
    "    result_idx_list = []\n",
    "    if search_type == 'lowest':\n",
    "        result_idx_list.append(np.argmin(data[search_item]))\n",
    "    elif search_type == 'highest':\n",
    "        result_idx_list.append(np.argmax(data[search_item]))\n",
    "    elif search_type == 'lower than':\n",
    "        result_idx_list = np.where(data[search_item] < search_value)[0]\n",
    "    elif search_type == 'higher than':\n",
    "        result_idx_list = np.where(data[search_item] > search_value)[0]\n",
    "    elif search_type == 'equal to':\n",
    "        result_idx_list = np.where(data[search_item] == search_value)[0]\n",
    "\n",
    "    return sentences[result_idx_list[0]], result_idx_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eda2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tkinter UI for chatapplication\n",
    "class ChatApplication:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.window = Tk()\n",
    "        self._setup_main_window()\n",
    "\n",
    "    def run(self):\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def _setup_main_window(self):\n",
    "        BG_GRAY = \"#59B8FF\"\n",
    "        BG_COLOR = \"#EEEEEE\"\n",
    "        BG_COLOR_2 = \"#F9F9F9\"\n",
    "        TEXT_COLOR = \"#000000\"\n",
    "\n",
    "        FONT = \"Helvetica 10\"\n",
    "        FONT_BOLD = \"Helvetica 12 bold\"\n",
    "\n",
    "        self.window.title('IMMABOT')\n",
    "        self.window.resizable(width=False, height=False)\n",
    "        self.window.configure(width=300, height=700, bg=BG_COLOR)\n",
    "\n",
    "        #head label\n",
    "        head_label = Label(self.window, bg=BG_GRAY, fg=TEXT_COLOR, text=\"Welcome to IMMABOT\", \n",
    "                           font=FONT_BOLD, pady=10)\n",
    "        head_label.place(relwidth=1)\n",
    "\n",
    "        # tiny divider\n",
    "\n",
    "        self.text_widget = Canvas(self.window, width=200, height=200,bg=\"white\")\n",
    "        self.text_widget.place(relheight=0.85, relwidth=1, rely=0.08)\n",
    "\n",
    "       \n",
    "\n",
    "        # bottom label\n",
    "        bottom_label = Label(self.window, bg=BG_GRAY, height=60)\n",
    "        bottom_label.place(relwidth=1, rely=0.9)\n",
    "\n",
    "        #message entry box\n",
    "        self.msg_entry = Entry(bottom_label, bg=BG_COLOR_2, fg=TEXT_COLOR, font=FONT)\n",
    "        self.msg_entry.place(relwidth=0.74, relheight=0.04, rely=0.008, relx=0.011)\n",
    "        self.msg_entry.focus()\n",
    "        self.msg_entry.bind(\"<Return>\", self._on_enter_pressed)\n",
    "\n",
    "        self.frame = Frame(self.text_widget, bg='white')\n",
    "\n",
    "        scrollbar = Scrollbar(self.frame, orient=\"vertical\", command=self.text_widget.yview)\n",
    "        #self.scrollable_frame_1 = Frame(self.text_widget)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.frame.bind(\n",
    "            \"<Configure>\",\n",
    "            lambda e: self.text_widget.configure(\n",
    "                scrollregion=self.frame.bbox(\"all\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.text_widget.create_window((0, 0), window=self.frame, anchor=\"nw\")\n",
    "        self.text_widget.configure(yscrollcommand=scrollbar.set)\n",
    "        # send button\n",
    "        send_button = Button(bottom_label, text=\"Send\", \n",
    "                             font=FONT_BOLD, width=20, \n",
    "                             bg=BG_COLOR_2, \n",
    "                             command=lambda: self._on_enter_pressed(None))\n",
    "        send_button.place(relx=0.77, rely=0.008, relheight=0.04, relwidth=0.22)\n",
    "\n",
    "        scrollbar.place(relx=0.95, rely=0.1, relheight=0.7)\n",
    "\n",
    "    def bot_bubble(self,master,x,y,color,choice,message=\"\"):\n",
    "        self.master = master\n",
    "        self.frame = Frame(self.master, bg=color)\n",
    "        #self.frame = self.scrollable_frame_1\n",
    "        self.i1 = self.master.create_window(x,y, window=self.frame)       \n",
    "        Label(self.frame,text=datetime.now().strftime(\"%d-%m-%Y %X\"),font=(\"Helvetica\", 7),bg=color).grid(row=0,column=0,sticky=\"w\",padx=5) #tarih saat        \n",
    "        Label(self.frame, text=textwrap.fill(message, 20), font=(\"Helvetica\", 9),bg=color).grid(row=1, column=0,sticky=\"w\",padx=5,pady=3)\n",
    "        self.window.update_idletasks()\n",
    "\n",
    "        if choice ==1:\n",
    "            p1,p2,p3,p4,p5,p6,(x1,y1,x2,y2) = self.draw_triangle_1(self.i1)\n",
    "            self.master.create_polygon((p1,p2,p3,p4,p5,p6), fill=color, outline=color)\n",
    "        else:\n",
    "            p1,p2,p3,p4,p5,p6,(x1,y1,x2,y2) = self.draw_triangle_2(self.i1)\n",
    "            self.master.create_polygon((p1,p2,p3,p4,p5,p6), fill=color, outline=color)\n",
    "\n",
    "        return (x1,y1,x2,y2)\n",
    "\n",
    "    def draw_triangle_1(self,widget):\n",
    "        x1, y1, x2, y2 = self.master.bbox(widget)\n",
    "        return x1, y2 - 10, x1 - 15, y2 + 10, x1, y2, (x1, y1, x2, y2)\n",
    "\n",
    "    def draw_triangle_2(self,widget):\n",
    "        x1, y1, x2, y2 = self.master.bbox(widget)\n",
    "        return x2, y2 - 10, x2 + 15, y2 + 10, x2, y2, (x1, y1, x2, y2)\n",
    "\n",
    "    def _on_enter_pressed(self, event):\n",
    "        msg = self.msg_entry.get()\n",
    "        self._insert_message(msg, \"You\")\n",
    "\n",
    "    def _insert_message(self, msg, sender):\n",
    "        if not msg:\n",
    "            return\n",
    "\n",
    "        if msg == 'flush()':\n",
    "            self.msg_entry.delete(0, END)\n",
    "            self.text_widget.delete(ALL)\n",
    "            global short_term_embedding\n",
    "            global first_question\n",
    "\n",
    "            short_term_embedding = 0\n",
    "            first_question = True\n",
    "        \n",
    "        else:\n",
    "            self.msg_entry.delete(0, END)\n",
    "            msg1 = f\"{sender}: {msg}\\n\\n\"\n",
    "            self.text_widget.configure(state=NORMAL)\n",
    "\n",
    "            input_message = msg1\n",
    "\n",
    "            if bubbles:      \n",
    "                self.text_widget.move(ALL, 0, -(60+int((bubbles[-1][-1]-bubbles[-1][1])/2)))\n",
    "                #self.scrollable_frame.move(ALL, 0, -80)\n",
    "\n",
    "            a = self.bot_bubble(self.text_widget,80,400, color=\"light green\", choice=1, message=input_message)\n",
    "            bubbles.append(a)\n",
    "\n",
    "            print(bubbles[-1][-1]-bubbles[-1][1])\n",
    "\n",
    "            answer = get_response(msg)\n",
    "            msg2 = f\"Bot: {answer}\\n\\n\"\n",
    "            output_message = msg2\n",
    "\n",
    "            if bubbles:      \n",
    "                self.text_widget.move(ALL, 0, -(60+int((bubbles[-1][-1]-bubbles[-1][1])/2)))\n",
    "        \n",
    "            b = self.bot_bubble(self.text_widget,200,420, color=\"light blue\", choice=2, message=output_message)\n",
    "            bubbles.append(b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4804405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for user-interaction\n",
    "def get_response(question):\n",
    "\n",
    "    if question == \"\":\n",
    "        return \"I'm sorry, I didn't get that.\"\n",
    "\n",
    "    question_edit = question\n",
    "    if question_edit[-1] in eos_tokens:\n",
    "        question_edit = question_edit[:-1]\n",
    "    question_edit += '?'\n",
    "\n",
    "    question_short = remove_stopword(question)\n",
    "    question_short = replace_word(question_short)\n",
    "    question_short_embedding = model_embedding.encode(question_short)       \n",
    "    question_embedding = model_embedding.encode(question_edit)\n",
    "    global short_term_embedding\n",
    "    global first_question\n",
    "\n",
    "    print(\"Question: \",question_edit)\n",
    "    print('--------------------------------------------------------')\n",
    "\n",
    "    context, true_answer, search_context, q_to_a, match_index = general_chat(data_pd, question_edit, question_embedding)\n",
    "\n",
    "    if true_answer:\n",
    "        answer = context\n",
    "        print(\"Answer before Paraphrasing: \", answer)\n",
    "        print('--------------------------------------------------------')\n",
    "    else:\n",
    "        answer = ''\n",
    "\n",
    "        if search_context:\n",
    "            context, short_term_embedding, first_question = context_search(question_edit, question_embedding, short_term_embedding, first_question)\n",
    "            q_to_a = True\n",
    "        else:\n",
    "            if first_question:\n",
    "                short_term_embedding = question_embedding*q_weight + sentences_embeddings[match_index]*a_weight\n",
    "            else:\n",
    "                short_term_embedding = short_term_embedding*memory_weight_1 + (question_embedding*q_weight + sentences_embeddings[match_index]*a_weight)*memory_weight_2\n",
    "            first_question = False\n",
    "            print(context)\n",
    "\n",
    "        if q_to_a:\n",
    "            #answer = context_to_answer(question_edit, context)\n",
    "            full_answer, answer_dict = proper_context(context, question_edit)\n",
    "            #answer = answer_dict['answer']\n",
    "            print(answer_dict)\n",
    "            if full_answer != ' ':\n",
    "                answer = full_answer\n",
    "            else:\n",
    "                answer = answer_dict['answer']\n",
    "\n",
    "            if answer_dict['score'] <= 0.10 and answer_dict['score'] > 0.01:\n",
    "                answer = \"I'm a bit unsure what you're asking for, but I found this: \" + answer\n",
    "            elif answer_dict['score'] <= 0.01:\n",
    "                answer = \"I found this:\"+ answer + \" But if this isn't what you're looking for, please rephrase your question?\"\n",
    "\n",
    "    answer = gpt_call(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e807e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Question:  hello?\n",
      "--------------------------------------------------------\n",
      "Answer before Paraphrasing:  Hello, thanks for visiting\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run this part to start application\n",
    "\n",
    "first_question = True\n",
    "eos_tokens = [\".\",\",\",\"!\",\"?\",\":\",\";\"]\n",
    "\n",
    "data = pd.read_csv(\"results_outlet_done.csv\", sep='|', error_bad_lines=False)\n",
    "data = np.array(data)\n",
    "\n",
    "data_pd = data_to_panda(data)\n",
    "\n",
    "app = ChatApplication()\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e57160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
